{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"19zMelfLB1yFSJmVhJGFmB09bm4912kvO","authorship_tag":"ABX9TyN+cydXLJ5x1XXjNdtFf3Uc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"id":"id7EQNhZkVFn","executionInfo":{"status":"error","timestamp":1692346110421,"user_tz":-480,"elapsed":5894,"user":{"displayName":"Viktor Fu","userId":"13010281786463940462"}},"outputId":"2bf8c5c0-d7eb-4e26-b059-6c314fef2837"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1b2c8e0496f6>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrgan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSRGAN_dataset_collate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRGANDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils_fit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfit_one_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import torch\n","import torch.backends.cudnn as cudnn\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.models.vgg import vgg19\n","\n","from nets.srgan import Discriminator, Generator\n","from utils.dataloader import SRGAN_dataset_collate, SRGANDataset\n","from utils.utils_fit import fit_one_epoch\n","\n","if __name__ == \"__main__\":\n","    #-------------------------------#\n","    #   是否使用Cuda\n","    #   没有GPU可以设置成False\n","    #-------------------------------#\n","    Cuda = True\n","    #-----------------------------------#\n","    #   代表进行四倍的上采样\n","    #-----------------------------------#\n","    scale_factor = 4\n","    #-----------------------------------#\n","    #   获得输入与输出的图片的shape\n","    #-----------------------------------#\n","    lr_shape = [96, 96]\n","    hr_shape = [lr_shape[0] * scale_factor, lr_shape[1] * scale_factor]\n","    #--------------------------------------------------------------------------#\n","    #   如果想要断点续练就将model_path设置成logs文件夹下已经训练的权值文件。\n","    #   当model_path = ''的时候不加载整个模型的权值。\n","    #\n","    #   此处使用的是整个模型的权重，因此是在train.py进行加载的。\n","    #   如果想要让模型从0开始训练，则设置model_path = ''。\n","    #--------------------------------------------------------------------------#\n","    G_model_path = \"\"\n","    D_model_path = \"\"\n","\n","    #------------------------------#\n","    #   训练参数设置\n","    #------------------------------#\n","    Init_epoch = 0\n","    Epoch = 200\n","    batch_size = 4\n","    lr = 0.0002\n","    #------------------------------#\n","    #   每隔50个step保存一次图片\n","    #------------------------------#\n","    save_interval = 50\n","    #------------------------------#\n","    #   获得图片路径\n","    #------------------------------#\n","    annotation_path = \"train_lines.txt\"\n","\n","    #---------------------------#\n","    #   生成网络和评价网络\n","    #---------------------------#\n","    G_model = Generator(scale_factor)\n","    D_model = Discriminator()\n","    #-----------------------------------#\n","    #   创建VGG模型，该模型用于提取特征\n","    #-----------------------------------#\n","    VGG_model = vgg19(pretrained=True)\n","    VGG_feature_model = nn.Sequential(*list(VGG_model.features)[:-1]).eval()\n","    for param in VGG_feature_model.parameters():\n","        param.requires_grad = False\n","\n","    #------------------------------------------#\n","    #   将训练好的模型重新载入\n","    #------------------------------------------#\n","    if G_model_path != '':\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        model_dict = G_model.state_dict()\n","        pretrained_dict = torch.load(G_model_path, map_location=device)\n","        pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) ==  np.shape(v)}\n","        model_dict.update(pretrained_dict)\n","        G_model.load_state_dict(model_dict)\n","    if D_model_path != '':\n","        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        model_dict = D_model.state_dict()\n","        pretrained_dict = torch.load(D_model_path, map_location=device)\n","        pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) ==  np.shape(v)}\n","        model_dict.update(pretrained_dict)\n","        D_model.load_state_dict(model_dict)\n","\n","    G_model_train = G_model.train()\n","    D_model_train = D_model.train()\n","\n","    if Cuda:\n","        cudnn.benchmark = True\n","        G_model_train = torch.nn.DataParallel(G_model)\n","        G_model_train = G_model_train.cuda()\n","\n","        D_model_train = torch.nn.DataParallel(D_model)\n","        D_model_train = D_model_train.cuda()\n","\n","        VGG_feature_model = torch.nn.DataParallel(VGG_feature_model)\n","        VGG_feature_model = VGG_feature_model.cuda()\n","\n","    # Binary Cross Entropy loss\n","    BCE_loss = nn.BCELoss()\n","    MSE_loss = nn.MSELoss()\n","\n","    with open(annotation_path) as f:\n","        lines = f.readlines()\n","    num_train = len(lines)\n","\n","    #------------------------------------------------------#\n","    #   Init_Epoch为起始世代\n","    #   Epoch总训练世代\n","    #------------------------------------------------------#\n","    if True:\n","        epoch_step      = min(num_train // batch_size, 2000)\n","        if epoch_step == 0:\n","            raise ValueError(\"数据集过小，无法进行训练，请扩充数据集。\")\n","        #------------------------------#\n","        #   Adam optimizer\n","        #------------------------------#\n","        G_optimizer     = optim.Adam(G_model_train.parameters(), lr=lr, betas=(0.9, 0.999))\n","        D_optimizer     = optim.Adam(D_model_train.parameters(), lr=lr, betas=(0.9, 0.999))\n","        G_lr_scheduler  = optim.lr_scheduler.StepLR(G_optimizer,step_size=1,gamma=0.98)\n","        D_lr_scheduler  = optim.lr_scheduler.StepLR(D_optimizer,step_size=1,gamma=0.98)\n","\n","        train_dataset   = SRGANDataset(lines, lr_shape, hr_shape)\n","        gen             = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=4, pin_memory=True,\n","                                    drop_last=True, collate_fn=SRGAN_dataset_collate)\n","\n","        for epoch in range(Init_epoch, Epoch):\n","            fit_one_epoch(G_model_train, D_model_train, G_model, D_model, VGG_feature_model, G_optimizer, D_optimizer, BCE_loss, MSE_loss, epoch, epoch_step, gen, Epoch, Cuda, batch_size, save_interval)\n","            G_lr_scheduler.step()\n","            D_lr_scheduler.step()"]}]}